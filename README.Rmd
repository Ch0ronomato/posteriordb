---
output:
  md_document:
    variant: markdown_github
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

[![Build Status](https://travis-ci.org/MansMeg/posteriordb.svg?branch=master)](https://travis-ci.org/MansMeg/posteriordb) [![codecov](https://codecov.io/gh/MansMeg/posteriordb/branch/master/graph/badge.svg)](https://codecov.io/gh/MansMeg/posteriordb)

# A Posterior Database (PDB) for Bayesian Inference

This repository contains data and models to produce posteriors based on different probabilistic programming languages (PPL). Currently, the focus is Stan, but it should be possible to use it with other frameworks as well.

## Purpose of the PDB

There are many purposes with the PDB

1. A simple repository to access many models and datasets in a structured way from R and Python
1. Store models and data in a structure that lends itself for testing inference algorithms on a large number of posteriors.
1. A structure that makes it easy for students to access models and data for courses in Bayesian data analysis.
1. A structure that is framework agnostic (although now Stan is in focus) and can be used with many different probabilistic programming frameworks.
1. A structure that simplifies regression testing of probabilistic programming frameworks.
1. Providing reliable gold standards for use in inference method development.

The long term goal is to move the posterior database to an open RESTful NoSQL database for easy access.

## Content

See [DATABASE_CONTENT.md](https://github.com/MansMeg/posteriordb/blob/master/doc/DATABASE_CONTENT.md) for the details content of the posterior database.

## Contributing

We are happy with any help in adding posteriors, data and models to the database! See [CONTRIBUTING.md](https://github.com/MansMeg/posteriordb/blob/master/doc/CONTRIBUTING.md) for the details on how to contribute.

## Using the posterior database from python
See [python README](./python/README.md)

## Using the posterior database from R (with the R package)

The included database contains convenience functions to access data, model code and information for individual posteriors.

To install the package, you can either clone this repository and run the following snippet to install the package in the cloned folder. The R package does not contain the content of the posterior database and hence the repository needs to be cloned.

```{r, eval = FALSE}
remotes::install("rpackage/")
```

It is also possible to install only the R package and then access the posteriors remotely.

```{r, eval = FALSE}
remotes::install_github("MansMeg/posteriordb", subdir = "rpackage/")
```

To load the package, just run.

```{r}
library(posteriordb)
```

First we create the posterior database to use, here we can use the database locally (if the repo is cloned).

```{r}
my_pdb <- pdb_local()
```

The above code requires that your working directory is in the main folder of the cloned repository. Otherwise we can use the `path` argument.

We can also simply use the github repository directly to access the data.

```{r, eval=FALSE}
my_pdb <- pdb_github()
```


Independent of the posterior database used, the following works for all.

To list the posteriors available in the database, use `posterior_names()`.

```{r}
pos <- posterior_names(my_pdb)
head(pos)
```

In the same fashion, we can list data and models included in the database as

```{r}
mn <- model_names(my_pdb)
head(mn)

dn <- data_names(my_pdb)
head(dn)
```

We can also get all information on each individual posterior as a tibble with

```{r}
pos <- posteriors_tbl_df(my_pdb)
head(pos)
```

The posterior's name is made up of the data and model fitted
to the data. Together, these two uniquely define a posterior distribution.
To access a posterior object we can use the model name.

```{r}
po <- posterior("eight_schools-eight_schools_centered", my_pdb)
```

From the posterior object, we can access data, model code (i.e., Stan code
in this case) and a lot of other useful information.

```{r}
dat <- get_data(po)
str(dat)

code <- stan_code(po)
code
```

We can also access the paths to data after they have been unzipped and copied to the R temp directory. By default, the model code is copied to the R temp directory.

```{r}
dfp <- data_file_path(po)
dfp

scfp <- stan_code_file_path(po)
scfp
```

We can also access information regarding the model and the data used to compute the posterior.

```{r}
data_info(po)
model_info(po)
```

Note that the references are referencing to BibTeX items that can be found in `content/references/references.bib`.

We can also access a list of posteriors with `filter_posteriors()`. The filtering function follows dplyr filter semantics based on the posterior tibble.

```{r}
tbl <- posteriors_tbl_df(my_pdb)
head(tbl)
pos <- filter_posteriors(my_pdb, data_name == "eight_schools")
pos
```

To access the gold standard posterior we can use the function `gold_standard_info()` to access information on how the gold standard posterior was computed. To access gold standard posterior draws we use `gold_standard_draws()`.

```{r}
gs_info <- gold_standard_info(po)
gs_info

gsd <- gold_standard_draws(po)
gsd
```

The function `gold_standard_draws()` returns a posterior `draws_list` object that can be summarized and transformed using the `posterior` package.

```{r}
draws_df <- posterior::as_draws_df(gsd$draws)
head(draws_df)
```


## Design choices (so far)

The main focus of the database is simplicity in data and model, both in understanding and in use.

The following are the current design choices in designing the posterior database.

1. Priors are hardcoded in model files as changing the prior changes the posterior.
   Create a new model to test different priors.
1. Data transformations are stored as different datasets.
   Create new data to test different data transformations, subsets, and variable settings. This makes the database larger/less memory efficient but simplifies the analysis of individual posteriors.
1. Models and data has (model/data).info.json files with model and data specific information.
1. Templates for different jsons can be found in content/templates and schemas in schemas (Note: these don't exist right now and will be added later)
1. Prefix 'syn_' stands for synthetic data where the generative process is known and can be found in content/data-raw.
1. All data preprocessing is included in content/data-raw.
1. Specific information for different PPL representations of models is included in the PPL syntax files as comments, not in the model.info.json files.
